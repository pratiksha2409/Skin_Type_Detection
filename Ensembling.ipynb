{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix,f1_score, precision_score, recall_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import cv2\n",
        "import pickle\n",
        "import random\n",
        "import os\n",
        "\n",
        "class Ensemble:\n",
        "    def __init__(self):\n",
        "        self.x_train = None\n",
        "        self.x_test = None\n",
        "        self.y_train = None\n",
        "        self.y_test = None\n",
        "        self.k = 4\n",
        "\n",
        "    def load_data(self, x_train, x_test, y_train, y_test):\n",
        "        self.x_train = x_train\n",
        "        self.x_test =  x_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "\n",
        "    def StackingClassifier(self):\n",
        "        # Define weak learners\n",
        "        weak_learners = [('svm', SVC()),\n",
        "                        ('rf', RandomForestClassifier()),\n",
        "                         ('knn', KNeighborsClassifier()),\n",
        "                        #('effnet', EfficientNetB0(weights='imagenet', include_top=False)),\n",
        "                         ]\n",
        "\n",
        "        # Finaler learner or meta model\n",
        "        final_learner = LogisticRegression()\n",
        "\n",
        "        train_meta_model = None\n",
        "        test_meta_model = None\n",
        "\n",
        "        # Start stacking\n",
        "        for clf_id, clf in weak_learners:\n",
        "            print(\"Classifier ID: \", clf_id)\n",
        "            # Predictions for each classifier based on k-fold\n",
        "            predictions_clf = self.k_fold_cross_validation(clf)\n",
        "\n",
        "            # Predictions for test set for each classifier based on train of level 0\n",
        "            test_predictions_clf = self.train_level_0(clf)\n",
        "\n",
        "            # Stack predictions which will form\n",
        "            # the inputa data for the data model\n",
        "            if isinstance(train_meta_model, np.ndarray):\n",
        "                train_meta_model = np.vstack((train_meta_model, predictions_clf))\n",
        "            else:\n",
        "                train_meta_model = predictions_clf\n",
        "\n",
        "            # Stack predictions from test set\n",
        "            # which will form test data for meta model\n",
        "            if isinstance(test_meta_model, np.ndarray):\n",
        "                test_meta_model = np.vstack((test_meta_model, test_predictions_clf))\n",
        "            else:\n",
        "                test_meta_model = test_predictions_clf\n",
        "\n",
        "        # Transpose train_meta_model\n",
        "        train_meta_model = train_meta_model.T\n",
        "\n",
        "        # Transpose test_meta_model\n",
        "        test_meta_model = test_meta_model.T\n",
        "\n",
        "        # Training level 1\n",
        "        self.train_level_1(final_learner, train_meta_model, test_meta_model)\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "    # Inside your Ensemble class\n",
        "    def k_fold_cross_validation(self, clf):\n",
        "        print(\"k-fold cross validation\")\n",
        "\n",
        "        predictions_clf = None\n",
        "\n",
        "        # Convert self.x_train to numpy array\n",
        "        self.x_train = np.array(self.x_train)\n",
        "\n",
        "        # Number of samples per fold\n",
        "        batch_size = int(len(self.x_train) / self.k)\n",
        "\n",
        "        # Start k-fold cross validation\n",
        "        for fold in range(self.k):\n",
        "            print(\"fold number: \", fold)\n",
        "            # Settings for each batch_size\n",
        "            if fold == (self.k - 1):\n",
        "                test = self.x_train[(batch_size * fold):, :]\n",
        "                batch_start = batch_size * fold\n",
        "                batch_finish = self.x_train.shape[0]\n",
        "            else:\n",
        "                test = self.x_train[(batch_size * fold): (batch_size * (fold + 1)), :]\n",
        "                batch_start = batch_size * fold\n",
        "                batch_finish = batch_size * (fold + 1)\n",
        "\n",
        "            # test & training samples for each fold iteration\n",
        "            fold_x_test = self.x_train[batch_start:batch_finish, :]\n",
        "            fold_x_train = self.x_train[[index for index in range(self.x_train.shape[0]) if\n",
        "                                        index not in range(batch_start, batch_finish)], :]\n",
        "\n",
        "            # test & training targets for each fold iteration\n",
        "            fold_y_test = self.y_train[batch_start:batch_finish]\n",
        "            # test & training targets for each fold iteration\n",
        "            fold_indices = [index for index in range(len(self.x_train)) if index not in range(batch_start, batch_finish)]\n",
        "            fold_y_train = [self.y_train[index] for index in fold_indices]\n",
        "\n",
        "            # Fit current classifier\n",
        "            clf.fit(fold_x_train, fold_y_train)\n",
        "            fold_y_pred = clf.predict(fold_x_test)\n",
        "\n",
        "            # Store predictions for each fold_x_test\n",
        "            if isinstance(predictions_clf, np.ndarray):\n",
        "                predictions_clf = np.concatenate((predictions_clf, fold_y_pred))\n",
        "            else:\n",
        "                predictions_clf = fold_y_pred\n",
        "\n",
        "        return predictions_clf\n",
        "\n",
        "\n",
        "    def train_level_0(self, clf):\n",
        "        print(\"train level-0\")\n",
        "        # Train in full real training set\n",
        "        clf.fit(self.x_train, self.y_train)\n",
        "        # Get predictions from full real test set\n",
        "        y_pred = clf.predict(self.x_test)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def train_level_1(self, final_learner, train_meta_model, test_meta_model):\n",
        "        print(\"train level-1\")\n",
        "        # Train is carried out with final learner or meta model\n",
        "        final_learner.fit(train_meta_model, self.y_train)\n",
        "        # Getting train and test accuracies from meta_model\n",
        "        print(f\"Train accuracy: {final_learner.score(train_meta_model, self.y_train)}\")\n",
        "        print(f\"Test accuracy: {final_learner.score(test_meta_model, self.y_test)}\")\n",
        "\n",
        "        predictions = final_learner.predict(test_meta_model)\n",
        "\n",
        "        print('Accuracy Stacking: ', accuracy_score(predictions, self.y_test))\n",
        "        print('Confusion matrix Stacking: ')\n",
        "        print(confusion_matrix(predictions, self.y_test))\n",
        "        #print('Classification report Stacking: ', classification_report(predictions, self.y_test))\n",
        "        print('F1-score Stacking: ', f1_score(predictions, self.y_test, average='weighted'))\n",
        "        print('Precision score Stacking: ', precision_score(predictions, self.y_test, average='weighted'))\n",
        "        #print('Recall score Stacking: ', recall_score(predictions, self.y_test, average='weighted'))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ensemble = Ensemble()\n",
        "\n",
        "    # dir = '/content/drive/MyDrive/skin-dataset/skin-dataset'\n",
        "    # categories = ['dry', 'normal','oily']\n",
        "\n",
        "    # data = []\n",
        "    # for category in categories:\n",
        "    #     cnt = 0\n",
        "    #     path = os.path.join(dir, category)\n",
        "    #     for img in os.listdir(path):\n",
        "    #         cnt += 1\n",
        "    #         img_array = cv2.imread(os.path.join(path, img))\n",
        "    #         #cv2.imshow('image', img_array)\n",
        "    #         try:\n",
        "    #             img_array = cv2.resize(img_array, (50, 50))\n",
        "    #             image = np.array(img_array).flatten()\n",
        "    #             data.append([image, categories.index(category)])\n",
        "    #         except Exception as e:\n",
        "    #             pass\n",
        "\n",
        "    #     print(f'{category} : {cnt} images')\n",
        "\n",
        "    # print(len(data))\n",
        "    # pick_in = open('data.pickle', 'wb')\n",
        "    # pickle.dump(data, pick_in)\n",
        "    # pick_in.close()\n",
        "\n",
        "    pick_in = open('data.pickle', 'rb')\n",
        "    data = pickle.load(pick_in)\n",
        "    pick_in.close()\n",
        "\n",
        "    random.shuffle(data)\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for feature, label in data:\n",
        "        features.append(feature)\n",
        "        labels.append(label)\n",
        "\n",
        "    xtrain, xtest, ytrain, ytest = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    ensemble.load_data(x_train = xtrain, x_test = xtest, y_train = ytrain, y_test = ytest)\n",
        "    ensemble.StackingClassifier()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQj2k2UBZKeS",
        "outputId": "c4135670-d8ed-43cf-891c-80efbe7404fb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier ID:  svm\n",
            "k-fold cross validation\n",
            "fold number:  0\n",
            "fold number:  1\n",
            "fold number:  2\n",
            "fold number:  3\n",
            "train level-0\n",
            "Classifier ID:  rf\n",
            "k-fold cross validation\n",
            "fold number:  0\n",
            "fold number:  1\n",
            "fold number:  2\n",
            "fold number:  3\n",
            "train level-0\n",
            "Classifier ID:  knn\n",
            "k-fold cross validation\n",
            "fold number:  0\n",
            "fold number:  1\n",
            "fold number:  2\n",
            "fold number:  3\n",
            "train level-0\n",
            "train level-1\n",
            "Train accuracy: 0.7918552036199095\n",
            "Test accuracy: 0.7297297297297297\n",
            "Accuracy Stacking:  0.7297297297297297\n",
            "Confusion matrix Stacking: \n",
            "[[64  7 12]\n",
            " [ 0  0  0]\n",
            " [ 7  4 17]]\n",
            "F1-score Stacking:  0.7719708772340352\n",
            "Precision score Stacking:  0.8218981487558467\n"
          ]
        }
      ]
    }
  ]
}